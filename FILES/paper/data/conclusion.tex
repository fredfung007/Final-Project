\section{Conclusion}
We presented a practical analysis of the robustness of two boosting algorithm, Adaboost and Deepboost.
We argued that uniformly introduced noise based on the distribution of sample does not reflect the realistic distribution.
We introduced a new realistic way of simulating noise in training data, and utilized it to introduce
noise into our experiments against these algorithms.
We also reported that both Adaboost and Deepboost has a good performance with the realistic noise we introduced.
This is different from Diettrich's work\cite{dietterich2000experimental}, in which noise is added according to the distribution of sample.
Our work coinincides with multiple reports that Adaboost has a good performance in general practice.

Our experimental result also shed some new light on analysing the robustness of other algorithms.
